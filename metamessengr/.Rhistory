summarise(n = n()) %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit() %>%
group_by(sender, n)
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit() %>%
group_by(sender, n)
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(used = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit() %>%
group_by(sender, used)
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data = data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(used = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit()
data %>%
group_by(sender, used)
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data = data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(used = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit()
data %>%
group_by(sender) %>%
arrange(used)
}
top_words(use)
?arrange
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data = data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(used = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit()
data %>%
group_by(sender, used) %>%
arrange(used, .by_group = TRUE)
}
?arrange
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data = data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(used = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit()
data %>%
group_by(sender, used) %>%
arrange(desc(used), .by_group = TRUE)
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data = data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(used = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit()
data %>%
group_by(sender) %>%
arrange(desc(used), .by_group = TRUE)
}
top_words(use)
document()
rm(list = c("clean_mess_text", "sender_sum", "top_words"))
document()
library(devtools)
library(roxygen2)
setwd("..")
install()
install("metamessengr")
using("purrr","jsonlite","dplyr","tidytext","tidyr","textdata","stringr",
"ggplot2","scales","chron","lexicon","ggraph","igraph", "tm")
using<-function(...) {
libs<-unlist(list(...))
req<-unlist(lapply(libs,require,character.only=TRUE))
need<-libs[req==FALSE]
if(length(need)>0){
install.packages(need)
lapply(need,require,character.only=TRUE)
}
}
using("purrr","jsonlite","dplyr","tidytext","tidyr","textdata","stringr",
"ggplot2","scales","chron","lexicon","ggraph","igraph", "tm")
stopwords()
stop_words
rm(tidytext)
detach("package:tidytext", unload=TRUE)
clean_mess_text <- function(data, custom_clean=NULL) {
data = data %>%
mutate(length = ifelse(nchar(content)>640, NA, nchar(content)),
content_unclean = content,
content = str_replace_all(content, "[^a-zA-Z0-9]", " "),
content = str_to_lower(content),
content = removeWords(content, stop_words$word),
content = str_squish(content),
convo = paste(sender,"-",sent_to)
) %>%
filter(!is.na(content),
content != "",
content != "connected messenger")
if(!is.null(custom_clean)) {
data %>%
mutate(
content = removeWords(content, custom_clean)
)
}
data
}
clean_mess_text()
me <- mess_selection(file_loc="C:/Users/meowy/OneDrive/Desktop/fbm_data_subset")
mess_selection <- function(file_loc) {
if(is.null(file_loc)){
file_loc = getwd()
}
wd <- getwd()
setwd(file_loc)
fns = list.files(recursive = T,
pattern = "\\.json$")
fns2 = str_extract(fns, "[^_]+")
inp = lapply(fns,
fromJSON)
l = as.numeric(length(map(inp,2)))
s = seq(from = 1, to = l)
f = NULL
for (i in s) {
if("content" %in% names(inp[[i]][[2]])){
t = map(inp,2)[[i]] %>%
select(timestamp_ms, sender_name, content) %>%
mutate(sent_to = sub("/message", "", fns2[[i]]))
if (i == 1){
f=t
} else {
f = rbind(f, t)
}
}
}
setwd(wd)
as.data.frame(f) %>%
rename(sender = sender_name)
}
me <- mess_selection(file_loc="C:/Users/meowy/OneDrive/Desktop/fbm_data_subset")
clean_mess_text(me)
%in%
`%in%`
library(fromJSON)
?as_tibble
dplyr::as_tibble
unnest_tokens
dplyr::unnest_tokens
?na.omit
document()
setwd("~/School stuff/Yale/BIS 620/fb_mess_final_proj/metamessengr")
document()
rm(list = c("clean_mess_text", "mess_selection"))
document()
document()
install.packages("magrittr")
library(migrittr)
install.packages("magrittr")
install.packages("magrittr")
`%>%`
library(magrittr)
%>%
`%>%`
library(usethis)
use_pipe()
document()
devtools::document()
base::as.Date(timestamp_ms),
base::as.Date(timestamp_ms)
base::sfds()
is.null
?is.null
?sub
??sub
?if
?`if`
mess_selection <- function(file_loc) {
if(base::is.null(file_loc)){
file_loc = getwd()
}
wd <- base::getwd()
base::setwd(file_loc)
fns = base::list.files(recursive = T,
pattern = "\\.json$")
fns2 = stringr::str_extract(fns, "[^_]+")
inp = base::lapply(fns,
jsonlite::fromJSON)
l = base::as.numeric(length(purrr::map(inp,2)))
s = base::seq(from = 1, to = l)
f = NULL
for (i in s) {
if("content" %in% base::names(inp[[i]][[2]])){
t = purrr::map(inp,2)[[i]] %>%
dplyr::select(timestamp_ms, sender_name, content) %>%
dplyr::mutate(sent_to = base::sub("/message", "", fns2[[i]]))
if (i == 1){
f=t
} else {
f = base::rbind(f, t)
}
}
}
base::setwd(wd)
base::as.data.frame(f) %>%
dplyr::rename(sender = sender_name)
}
me <- mess_selection(file_loc="C:/Users/meowy/OneDrive/Desktop/fbm_data_subset")
clean_mess_time <- function(data) {
data %>%
dplyr::mutate(timestamp_ms = timestamp_ms/1000,
timestamp_ms = base::as.POSIXct(timestamp_ms,
origin="1970-01-01",
tz="America/Los_Angeles"),
date = base::as.Date(timestamp_ms),
time = base::strftime(timestamp_ms, format="%H:%M:%S"),
time = chron::chron(times=time),
time = base::as.numeric(time),
hour = time *24)
}
me_time <- clean_mess_time(me)
nchar
?nchar
?is.na
clean_mess_text <- function(data, custom_clean=NULL) {
data = data %>%
dplyr::mutate(length = base::ifelse(base::nchar(content)>640, NA,
base::nchar(content)),
content_unclean = content,
content = stringr::str_replace_all(content, "[^a-zA-Z0-9]", " "),
content = stringr::str_to_lower(content),
content = tm::removeWords(content, stop_words$word),
content = stringr::str_squish(content),
convo = base::paste(sender,"-",sent_to)
) %>%
dplyr::filter(!base::is.na(content),
content != "",
content != "connected messenger")
if(!base::is.null(custom_clean)) {
data %>%
dplyr::mutate(
content = tm::removeWords(content, custom_clean)
)
}
data
}
me_text <- clean_mess_text(me)
?data
clean_mess_text <- function(data, custom_clean=NULL) {
stop_words <- data("stop_words")
data <-  data %>%
dplyr::mutate(length = base::ifelse(base::nchar(content)>640, NA,
base::nchar(content)),
content_unclean = content,
content = stringr::str_replace_all(content, "[^a-zA-Z0-9]", " "),
content = stringr::str_to_lower(content),
content = tm::removeWords(content, stop_words$word),
content = stringr::str_squish(content),
convo = base::paste(sender,"-",sent_to)
) %>%
dplyr::filter(!base::is.na(content),
content != "",
content != "connected messenger")
if(!base::is.null(custom_clean)) {
data %>%
dplyr::mutate(
content = tm::removeWords(content, custom_clean)
)
}
data
}
me_text <- clean_mess_text(me)
stop_words <- data("stop_words")
tidytext::get_stopwords()
stopwords::get_stopwords()
stopwords::data_stopwords_snowball
clean_mess_text <- function(data, custom_clean=NULL) {
data <-  data %>%
dplyr::mutate(length = base::ifelse(base::nchar(content)>640, NA,
base::nchar(content)),
content_unclean = content,
content = stringr::str_replace_all(content, "[^a-zA-Z0-9]", " "),
content = stringr::str_to_lower(content),
content = tm::removeWords(content, stopwords::data_stopwords_snowball$en),
content = stringr::str_squish(content),
convo = base::paste(sender,"-",sent_to)
) %>%
dplyr::filter(!base::is.na(content),
content != "",
content != "connected messenger")
if(!base::is.null(custom_clean)) {
data %>%
dplyr::mutate(
content = tm::removeWords(content, custom_clean)
)
}
data
}
me_text <- clean_mess_text(me)
me_text
tidytext::stop_words
clean_mess_text <- function(data, custom_clean=NULL) {
data <-  data %>%
dplyr::mutate(length = base::ifelse(base::nchar(content)>640, NA,
base::nchar(content)),
content_unclean = content,
content = stringr::str_replace_all(content, "[^a-zA-Z0-9]", " "),
content = stringr::str_to_lower(content),
content = tm::removeWords(content, tidytext::stop_words$word),
content = stringr::str_squish(content),
convo = base::paste(sender,"-",sent_to)
) %>%
dplyr::filter(!base::is.na(content),
content != "",
content != "connected messenger")
if(!base::is.null(custom_clean)) {
data %>%
dplyr::mutate(
content = tm::removeWords(content, custom_clean)
)
}
data
}
me_text <- clean_mess_text(me)
me_text
me_text$content
?n
?desc
?ifelse
document()
devtools::document
devtools::document()
rm(list = c("clean_mess_text", "clean_mess_time", "mess_selection"))
devtools::document()
?lexicon::grady_augmented
lexicon::grady_augmented
tidytext::stop_words
library(devtools)
library(roxygen2)
document()
lexicon::grady_augmented
document()
detach(lexicon)
detach("lexicon")
top_words <- function(data) {
grady_augmented=dplyr::as_tibble(data(lexicon::grady_augmented))
grady_augmented=dplyr::rename(grady_augmented, words=value)
data = data %>%
tidytext::unnest_tokens(input = content,
output = "words",
token = "words") %>%
dplyr::semi_join(grady_augmented) %>%
dplyr::group_by(sender, words) %>%
dplyr::summarise(used = dplyr::n()) %>%
dplyr::ungroup() %>%
dplyr::mutate(sender = base::ifelse(sender=="",NA,sender)) %>%
stats::na.omit()
data %>%
dplyr::group_by(sender) %>%
dplyr::arrange(dplyr::desc(used), .by_group = TRUE)
}
top_words(me_text)
top_words <- function(data) {
grady_augmented=dplyr::as_tibble(lexicon::grady_augmented)
grady_augmented=dplyr::rename(grady_augmented, words=value)
data = data %>%
tidytext::unnest_tokens(input = content,
output = "words",
token = "words") %>%
dplyr::semi_join(grady_augmented) %>%
dplyr::group_by(sender, words) %>%
dplyr::summarise(used = dplyr::n()) %>%
dplyr::ungroup() %>%
dplyr::mutate(sender = base::ifelse(sender=="",NA,sender)) %>%
stats::na.omit()
data %>%
dplyr::group_by(sender) %>%
dplyr::arrange(dplyr::desc(used), .by_group = TRUE)
}
top_words(me_text)
document()
usethis::use_data(lexicon::grady_augmented, metamessengr)
usethis::use_data(lexicon::grady_augmented)
grady_augmented <- lexicon::grady_augmented
usethis::use_data(grady_augmented)
document()
rm(list = c("top_words"))
document()
document()
usethis::use_data(stop_words)
?lexicon::grady_augmented
length(grady_augmented)
document()
?stop_words
document()
document()
document()
install.packages("testthat")
install.packages("testthat")
library(testthat)
devtools::test()
use_test()
load_all()
library(devtools)
library(roxygen2)
load_all()
check()
?data
document()
check()
use_gpl3_license()
check()
test_that("multiplication works", {
expect_equal(2 * 2, 4)
})
build()
devtools::install("../metamessengr")
library(devtools)
install("../metamessengr")
library(devtools)
install.packages("usethis")
library(usethis)
library(devtools)
install("../metamessengr")
library(devtools)
install("../metamessengr")
?clean_mess_time
library(metamessengr)
?clean_mess_time
?clean_mess_text
library(devtools)
document()
check()
install("../metamessengr")
library(metamessengr)
?clean_mess_text
?clean_mess_time
install.packages("help")
