content = str_replace_all(content, "[^a-zA-Z0-9]", " "),
content = str_to_lower(content),
content = removeWords(content, stop_words$word),
content = ifelse(
!is.null(custom_clean),
removeWords(content, custom_clean)
),
content = str_squish(content),
convo = paste(sender,"-",sent_to)
) %>%
filter(!is.na(content),
content != "",
content != "connected messenger")
}
me_text <- clean_mess_text(me)
clean_mess_text <- function(data, custom_clean=NULL) {
tidy_text <- data %>%
mutate(length = ifelse(nchar(content)>640, NA, nchar(content)),
content_unclean = content,
content = str_replace_all(content, "[^a-zA-Z0-9]", " "),
content = str_to_lower(content),
content = removeWords(content, stop_words$word),
content = ifelse(
!is.null(custom_clean),
removeWords(content, custom_clean), content),
content = str_squish(content),
convo = paste(sender,"-",sent_to)
) %>%
filter(!is.na(content),
content != "",
content != "connected messenger")
}
me_text <- clean_mess_text(me)
me_text_time <- clean_mess_text(me_time)
me_time_text <- clean_mess_time(me_text)
?stop_words
str_to_lower()
str_to_lower
?str_to_lower
?lubridate
document()
setwd("C:/Users/meowy/OneDrive/Documents/School stuff/Yale/BIS 620/fb_mess_final_proj/metamessengr")
document()
rm(list = c("clean_mess_text"))
document()
document()
document()
document()
sender_sum <- function(data) {
data %>%
group_by(sender,sent_to) %>%
summarise(count = n(),
length = sum(length, na.rm = T))
}
sender_sum(me_text_time)
sender_sum <- function(data) {
data %>%
group_by(sender,sent_to) %>%
summarise(count = n(),
length = sum(length, na.rm = T))
}
sender_sum(me_text_time)
as.data.frame(sender_sum(me_text_time))
sent_to_sum <- function(data) {
data %>%
group_by(sent_to) %>%
summarise(count = n(),
length = sum(length, na.rm = T))
}
sent_to_sum(me_time_text)
top_words <- function(data) {
data %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
ungroup()
}
top_words(me_time_text)
data <- me_time_text
unnest_tokens(data,
input = content_c,
output = "words",
token = "words")
unnest_tokens(data,
input = content,
output = "words",
token = "words")
tail(unnest_tokens(data,
input = content,
output = "words",
token = "words"))
data
data
me_time_text
me_text_time
data$content
tail(data$content)
tail(me_text)
custom_clean
clean_mess_text <- function(data, custom_clean=NULL) {
tidy_text <- data %>%
mutate(length = ifelse(nchar(content)>640, NA, nchar(content)),
content_unclean = content,
content = str_replace_all(content, "[^a-zA-Z0-9]", " "),
content = str_to_lower(content),
content = removeWords(content, stop_words$word),
content = ifelse(
!is.null(custom_clean),
removeWords(content, custom_clean), content),
content = str_squish(content),
convo = paste(sender,"-",sent_to)
) %>%
filter(!is.na(content),
content != "",
content != "connected messenger")
}
me
clean_mess_text(me)
clean_mess_text <- function(data, custom_clean=NULL) {
data %>%
mutate(length = ifelse(nchar(content)>640, NA, nchar(content)),
content_unclean = content,
content = str_replace_all(content, "[^a-zA-Z0-9]", " "),
content = str_to_lower(content),
content = removeWords(content, stop_words$word),
content = ifelse(
!is.null(custom_clean),
removeWords(content, custom_clean), content),
content = str_squish(content),
convo = paste(sender,"-",sent_to)
) %>%
filter(!is.na(content),
content != "",
content != "connected messenger")
}
clean_mess_text(me)
clean_mess_text <- function(data, custom_clean=NULL) {
data %>%
mutate(length = ifelse(nchar(content)>640, NA, nchar(content)),
content_unclean = content,
content = str_replace_all(content, "[^a-zA-Z0-9]", " "),
content = str_to_lower(content),
content = removeWords(content, stop_words$word),
# content = ifelse(
#   !is.null(custom_clean),
#   removeWords(content, custom_clean), content),
content = str_squish(content),
convo = paste(sender,"-",sent_to)
) %>%
filter(!is.na(content),
content != "",
content != "connected messenger")
}
clean_mess_text(me)
is.null(sdf)
clean_mess_text <- function(data, custom_clean=NULL) {
data = data %>%
mutate(length = ifelse(nchar(content)>640, NA, nchar(content)),
content_unclean = content,
content = str_replace_all(content, "[^a-zA-Z0-9]", " "),
content = str_to_lower(content),
content = removeWords(content, stop_words$word),
content = str_squish(content),
convo = paste(sender,"-",sent_to)
) %>%
filter(!is.na(content),
content != "",
content != "connected messenger")
if(!is.null(custom_clean)) {
data %>%
mutate(
content = removeWords(content, custom_clean)
)
}
}
clean_mess_text(me)
clean_mess_text <- function(data, custom_clean=NULL) {
data = data %>%
mutate(length = ifelse(nchar(content)>640, NA, nchar(content)),
content_unclean = content,
content = str_replace_all(content, "[^a-zA-Z0-9]", " "),
content = str_to_lower(content),
content = removeWords(content, stop_words$word),
content = str_squish(content),
convo = paste(sender,"-",sent_to)
) %>%
filter(!is.na(content),
content != "",
content != "connected messenger")
if(!is.null(custom_clean)) {
data %>%
mutate(
content = removeWords(content, custom_clean)
)
}
data
}
clean_mess_text(me)
C=c("yall", "ll")
clean_mess_text(me, custom_clean = C)
top_words <- function(data) {
data %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
ungroup()
}
use <- me %>%
clean_mess_text() %>%
clean_mess_time()
top_words(use)
data %>%
unnest_tokens(tidy_text,
input = content_c,
output = "words",
token = "words") %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
ungroup()
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
ungroup()
top_words <- function(data) {
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
ungroup()
}
top_words(use)
top_words <- function(data) {
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate_all(na_if,"")
}
top_words(use)
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate_all(na_if,""),
na.omit()
top_words <- function(data) {
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate_all(na_if,""),
na.omit()
}
top_words <- function(data) {
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate_all(na_if,"") %>%
na.omit()
}
top_words(use)
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented
grady_augmented=rename(grady_augmented, words=value)
grady_augmented
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate_all(na_if,"") %>%
na.omit()
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
group_by(sender, n) %>%
mutate_all(na_if,"") %>%
na.omit()
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
mutate_all(na_if,"") %>%
na.omit() %>%
group_by(sender, n)
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
mutate_all(na_if,"") %>%
na.omit()
}
top_words(use)
?na_if
ifelse
?ifelse
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit()
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit() %>%
group_by(sender, n)
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit() %>%
group_by(sender, n)
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(used = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit() %>%
group_by(sender, used)
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data = data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(used = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit()
data %>%
group_by(sender, used)
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data = data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(used = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit()
data %>%
group_by(sender) %>%
arrange(used)
}
top_words(use)
?arrange
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data = data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(used = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit()
data %>%
group_by(sender, used) %>%
arrange(used, .by_group = TRUE)
}
?arrange
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data = data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(used = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit()
data %>%
group_by(sender, used) %>%
arrange(desc(used), .by_group = TRUE)
}
top_words(use)
top_words <- function(data) {
data("grady_augmented")
grady_augmented=as_tibble(grady_augmented)
grady_augmented=rename(grady_augmented, words=value)
data = data %>%
unnest_tokens(input = content,
output = "words",
token = "words") %>%
semi_join(grady_augmented) %>%
group_by(sender, words) %>%
summarise(used = n()) %>%
ungroup() %>%
mutate(sender = ifelse(sender=="",NA,sender)) %>%
na.omit()
data %>%
group_by(sender) %>%
arrange(desc(used), .by_group = TRUE)
}
top_words(use)
document()
rm(list = c("clean_mess_text", "sender_sum", "top_words"))
document()
